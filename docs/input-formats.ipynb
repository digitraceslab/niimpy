{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File formats\n",
    "\n",
    "In principle, Niimpy can deal with any files of any format - you only need to convert them to a DataFrame.  Still, it is very useful to have some common formats, so we present two standard formats with default readers:\n",
    "\n",
    "* **CSV files** are very standard and normal to create and understand, but in order to deal with them everything must be loaded into memory.\n",
    "* **sqlite3 databases**, which requires sqlite3 to read, but provides more power for filtering and automatic processing without reading everything into memory.\n",
    "* **Google TakeOut** provides a large selection of data in different formats. We provide readers most commonly used data types.\n",
    "* **MHealth** is a common format for health data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame format (in-memory)\n",
    "\n",
    "In-memory, data is stored in a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).  This is basically a normal dataframe.  There are some standardized columns (see the [schema](schema.html)) and the index is a DatetimeIndex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files\n",
    "\n",
    "CSV files should have a header that lists the column names and generally be readable by `pandas.read_csv`.\n",
    "\n",
    "Reading these can be done with `niimpy.read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import niimpy \n",
    "import niimpy.config as config\n",
    "\n",
    "# Read the battery data\n",
    "df= niimpy.read_csv(config.MULTIUSER_AWARE_BATTERY_PATH, tz='Europe/Helsinki')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sqlite3 databases\n",
    "\n",
    "For the purposes of niimpy, sqlite3 databases can generally be seen as supercharged CSV files.\n",
    "\n",
    "A single database file could contain multiple datasets within it, thus when reading them a **table name** must be specified.\n",
    "\n",
    "One reads the entire database into memory using `sqlite.read_sqlite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sqlite3 data\n",
    "df= niimpy.read_sqlite(config.SQLITE_SINGLEUSER_PATH, table=\"AwareScreen\", tz='Europe/Helsinki')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list the tables within a database using `niimpy.reading.read.read_sqlite_tables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "niimpy.reading.read.read_sqlite_tables(config.SQLITE_SINGLEUSER_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlite3 files are highly recommended as a data storage format, since many common exploration options can be done within the database itself without reading the whole data into memory or writing an iterator.  However, the interface is more difficult to use.  Niimpy (before 2021-07) used this as its primary interface, but since then this interface has been de-emphasized.  You can read more in [the database section](database.html), but this is only recommended if you need efficiency when using massive amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google TakeOut\n",
    "\n",
    "Google takeout contains a many different types of data and new types are added as Google creates services or changes data storage methods. Readers are currently available for location data, emails, and activity data from the fit app. For other data types, the user needs to manually convert them into a Niimpy compatible Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloaded from Google Takeout is compressed as a zip archive to conserve disk space. To \n",
    "# demonstrate reading for the zip file, we will first compress our example data into the zip format.\n",
    "import zipfile\n",
    "test_zip = zipfile.ZipFile(\"test.zip\", mode=\"w\")\n",
    "\n",
    "for dirpath,dirs,files in os.walk(config.GOOGLE_TAKEOUT_DIR):\n",
    "    for f in files:\n",
    "        filename = os.path.join(dirpath, f)\n",
    "        filename_in_zip = filename.replace(config.GOOGLE_TAKEOUT_DIR, \"\")\n",
    "        test_zip.write(filename, filename_in_zip)\n",
    "\n",
    "test_zip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we read location data from the zip file.\n",
    "import niimpy\n",
    "import niimpy.config as config\n",
    "import niimpy.preprocessing.location as nilo\n",
    "\n",
    "data = niimpy.reading.google_takeout.location_history(\"test.zip\")\n",
    "data = nilo.filter_location(\n",
    "    data,\n",
    "    latitude_column = \"latitude\",\n",
    "    longitude_column = \"longitude\",\n",
    "    remove_disabled=False, remove_network=False, remove_zeros=True\n",
    ")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity data is read similarly. The data contains many columns with missing data, so in order to use the step count data, for example, we must set the NaN values to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = niimpy.reading.google_takeout.activity(\"test.zip\")\n",
    "data.loc[data[\"step_count\"].isna(), \"step_count\"] = 0\n",
    "data[[\"calories_(kcal)\", \"step_count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `google_takeout.email_activity` and `google_takeout.chat` function will read and process all emails in the GMail mailbox and all Google chat messages respectively. They return a dataframe containing metadata and statistics of each message. Email addresses, email IDs and names are replaced by numerical indexes.\n",
    "\n",
    "The email files can be large and processing them could take some time. You can also include sentiment analysis of each email using the `sentiment` parameter. For this, we recommend using a system with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niimpy.reading.google_takeout.email_activity(\"test.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niimpy.reading.google_takeout.chat(\"test.zip\", sentiment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a reader for extracting Youtube watch history data. We do not, by default, return video identifiers, but replace them with numerical IDs. The only available information then is the recorded time, which corresponds to video start time.\n",
    "\n",
    "Importantly, we have no information on how long the user watched a given video, as this is not stored in the TakeOut data. You can deduce whether the user has rewatched a given video, watched multiple videos in a row, or started another video quickly without finishing the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niimpy.reading.google_takeout.youtube_watch_history(\"test.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Google takeout may provide the mailbox as a single uncompressed file, it is also possible to provide it's file path directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(config.GOOGLE_TAKEOUT_DIR, \"Takeout\", \"Mail\", \"All mail Including Spam and Trash.mbox\")\n",
    "niimpy.reading.google_takeout.email_activity(path, sentiment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject Downloads their Google TakeOut data as a separate zip file. The Zipfile package, which is included in the Python standard, is convenient for reading the data files contained in the zip file. For example, one could read the location data with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "zip_file = ZipFile(\"test.zip\")\n",
    "json_data  = zip_file.read(\"Takeout/Location History (Timeline)/Records.json\")\n",
    "json_data = json.loads(json_data)\n",
    "data = pd.json_normalize(json_data[\"locations\"])\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location data is stored in the json format. Other types of data are stored in various formats and with different files structures. The user must find how each type of data they need is stored and how it can be read in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHealth\n",
    "\n",
    "We have implemented readers for 3 data types formatted according to the [MHealth schema](https://www.openmhealth.org/documentation/#/schema-docs/schema-library). These are total sleep time, heart rate and geolocation. Other data types may be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading total sleep time data:\n",
    "filename = config.MHEALTH_TOTAL_SLEEP_TIME_PATH\n",
    "niimpy.reading.mhealth.total_sleep_time_from_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading heart rate data:\n",
    "filename = config.MHEALTH_HEART_RATE_PATH\n",
    "niimpy.reading.mhealth.heart_rate_from_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading geolocation data:\n",
    "filename = config.MHEALTH_GEOLOCATION_PATH\n",
    "niimpy.reading.mhealth.geolocation_from_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/24/rantahj1/unix/miniconda3/envs/niimpy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import niimpy.reading.google_takeout as takeout\n",
    "\n",
    "zip_filename = \"../data/takeout-jarno-001.zip\"\n",
    "datatypes = takeout.fit_list_data(zip_filename)\n",
    "datatypes = datatypes[\n",
    "    datatypes[\"content\"].str.contains(\"step_count.delta\") &\n",
    "    datatypes[\"source\"].str.contains(\"polarflow\")\n",
    "]\n",
    "filename = datatypes[\"filename\"].iloc[0]\n",
    "\n",
    "data = takeout.fit_read_data(zip_filename, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   3,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  16,  15,  17,  18,  19,  20,  21,  23,  22,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,\n",
       "        64,  72,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,\n",
       "        83,  78,  79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  98,  97,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 126, 125, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 138, 137, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 156, 153, 157,\n",
       "       155, 154, 159, 160, 158, 161, 164, 163, 162, 165, 166, 167, 168,\n",
       "       169, 171, 170, 172])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other formats\n",
    "\n",
    "You can add readers for any types of formats which you can convert into a Pandas dataframe (so basically anything).  For examples of readers, see `niimpy/reading/read.py`.  Apply the function `niimpy.preprocessing.util.df_normalize` in order to apply some standardizations to get the standard Niimpy format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
